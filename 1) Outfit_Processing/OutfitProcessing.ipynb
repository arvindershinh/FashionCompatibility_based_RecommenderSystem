{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OutfitProcessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTQpgYJo2500JAgqJN0+/q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import json\n","import os\n","import random\n","import sys"],"metadata":{"id":"54bRLqkYG896"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Iterator, Mapping\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","from typing import Any, NamedTuple"],"metadata":{"id":"z_RZnB1APvlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","from numpy import asarray\n","import jax.numpy as jnp\n","import jax\n","from jax import jit\n","from jax import random"],"metadata":{"id":"GwZqUXvz8jE6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transferlearningresnet as resnetModel"],"metadata":{"id":"dZ3PayIuLSaj","executionInfo":{"status":"ok","timestamp":1650719862835,"user_tz":-330,"elapsed":533,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/gdrive')"],"metadata":{"id":"mzh0ENXgqyK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def wordDictionary(path):\n","  tokens_series = pd.read_csv(path, delimiter='\\s+', header=0, names=['Token', 'Frequency'], usecols=[0]).squeeze()\n","  # tokens_series.index = tokens_series.index+1\n","  tokens = {tokens_series.values[i]: tokens_series.index[i] for i in range(tokens_series.shape[0])}\n","  return tokens"],"metadata":{"id":"GifOOUL7zCc9","executionInfo":{"status":"ok","timestamp":1650719865777,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["# fashion_tokens = wordDictionary('gdrive/MyDrive/Colab Notebooks/Capstone Project/Outfit_Processing/Data/final_word_dict.txt')\n","# fashion_tokens\n","# len(fashion_tokens)\n","# 2755\n","# list(fashion_tokens.values())[-1]"],"metadata":{"id":"_AS_2o4Hnkw5","executionInfo":{"status":"ok","timestamp":1650719867177,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def to_sequence_Array(set_info, InceptionV3_InputImageDim, tokenDic, dataPath):\n","\n","  \"\"\"Builds a SequenceExample proto for an outfit.\n","  \"\"\"\n","  set_id = set_info['set_id']\n","  image_data = []\n","  image_ids = []\n","  caption_data = []\n","  caption_ids = []\n","  \n","  dict_len = len(tokenDic)\n","\n","  outfit_path = os.path.join(dataPath, 'Outfits', str(set_id))\n","\n","  if not(os.path.exists(outfit_path)):\n","    return\n","    \n","  def fixedLength_ImageAndCaption_Seq(img_caption_Seq, fixedSeqLength):\n","    imgSeq, captionSeq = img_caption_Seq\n","    assert len(imgSeq) == len(captionSeq)\n","    \n","    l = len(imgSeq)\n","    if l > fixedSeqLength:\n","      return imgSeq[:fixedSeqLength], captionSeq[:fixedSeqLength]\n","    elif l < fixedSeqLength:\n","      return imgSeq+[imgSeq[-1]]*(fixedSeqLength-l), captionSeq+[captionSeq[-1]]*(fixedSeqLength-l)\n","    else:\n","      return imgSeq, captionSeq\n","\n","  def imageProcessing(filename):\n","    image = Image.open(filename)\n","    img_resized = image.resize(InceptionV3_InputImageDim)\n","    img_numpy =  asarray(img_resized)\n","    return img_numpy\n","\n","  def captionProcessing(caption):\n","\n","    def oneHotEncoding(tokenIds, vectorLength):\n","      zeroVector = [0]*vectorLength\n","      oneHotVectors = [zeroVector[:i]+[1]+zeroVector[i+1:] for i in tokenIds]\n","      oneHotVectorsArray = np.array(oneHotVectors, dtype=jnp.float32)\n","      return oneHotVectorsArray\n","\n","    token_ids = [tokenDic.get(word, dict_len) for word in caption.split()]\n","    if not(len(token_ids)):\n","      token_ids = [dict_len]\n","    oneHotVectors = oneHotEncoding(token_ids, dict_len+1)\n","    oneHotEmbedding = np.sum(oneHotVectors, axis=0)\n","    return oneHotEmbedding\n","  \n","  for image_info in set_info['items']:\n","    \n","    imagefile = os.path.join(outfit_path, str(image_info['index']) + '.jpg')\n","    image = imageProcessing(imagefile)\n","    image_data.append(image)\n","\n","    caption = image_info['name']\n","    oneHotEncoding = captionProcessing(caption)\n","    caption_data.append(oneHotEncoding)\n","\n","  image_data, caption_data = fixedLength_ImageAndCaption_Seq((image_data, caption_data), 8)\n","\n","  caption_feature = np.array(caption_data)\n","\n","  # Feature extraction using transfer learning (resnet)\n","  image_np_array = np.array(image_data)\n","  model = resnetModel.getResNetModel(image_np_array.shape[1:])\n","  image_feature = model.predict(image_np_array)\n","  \n","  return (image_feature, caption_feature)"],"metadata":{"id":"q5E77YVriRwE","executionInfo":{"status":"ok","timestamp":1650720304953,"user_tz":-330,"elapsed":701,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["# json_file = 'gdrive/MyDrive/Colab Notebooks/Capstone Project/Outfit_Processing/Data/outfit.json'"],"metadata":{"id":"TB0y3KfcGk92","executionInfo":{"status":"ok","timestamp":1650719882686,"user_tz":-330,"elapsed":2,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["# all_sets = json.load(open(json_file))\n","# all_sets[0]"],"metadata":{"id":"QPTDuwLWlp4r","executionInfo":{"status":"ok","timestamp":1650719887292,"user_tz":-330,"elapsed":817,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["def to_sequence_Tensor(outfits, InceptionV3_InputImageDim, tokenDic, path):\n","\n","  outfitSequencesImage = []\n","  outfitSequencesCaption = []\n","\n","  for outfit in outfits:\n","    img_caption_seq = to_sequence_Array(outfit, InceptionV3_InputImageDim, tokenDic, path)\n","    if img_caption_seq:\n","      image_seq, caption_seq = img_caption_seq\n","      outfitSequencesImage.append(image_seq)\n","      outfitSequencesCaption.append(caption_seq)\n","\n","  return {'outfitSequencesImage' : jnp.array(outfitSequencesImage, dtype=jnp.float32), 'outfitSequencesCaption' : jnp.array(outfitSequencesCaption, dtype=jnp.float32)}"],"metadata":{"id":"KxZ8vjnQpFaH","executionInfo":{"status":"ok","timestamp":1650720310998,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["# path = 'gdrive/MyDrive/Colab Notebooks/Capstone Project/Outfit_Processing/Data/'\n","# sequence_Tensor = to_sequence_Tensor(all_sets, (224,224), fashion_tokens, path)"],"metadata":{"id":"gfRA8kzFmewj","executionInfo":{"status":"ok","timestamp":1650720337058,"user_tz":-330,"elapsed":17224,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["# sequence_Tensor['outfitSequencesImage'].shape, sequence_Tensor['outfitSequencesCaption'].shape"],"metadata":{"id":"KotHiLpWyKcU","executionInfo":{"status":"ok","timestamp":1650720339809,"user_tz":-330,"elapsed":532,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"57c00741-a41f-4770-88f3-2b85776041ba"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3, 8, 100352), (3, 8, 2756))"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["CACHE"],"metadata":{"id":"bFsuZ85m9l9U"}},{"cell_type":"code","source":["# ((1700, 8, 100352), (1700, 8, 2756))\n","\n","# ((5, 8, 100352), (5, 8, 2756)) 1\n","# ((5, 8, 100352), (5, 8, 2756)) 2\n","# ((5, 8, 100352), (5, 8, 2756)) 3\n","\n","# (8, 100352)  --> wRNN*Img --> (8, 512)   RNN_E\n","# (8, 100352)  --> wVS*Img -->  (8, 512)   VS_E\n","# (8, 2756)   --> Caption\n","\n","# RNN_E --> Bi-LSTM model --> obj (B+F)\n","# VS_E, Caption   --> VS_Model (VS_E, Caption_512)  --> obj_VS\n","\n","# Obj = Module (obj (B+F) + obj_VS)\n","\n","# gObj =  Gradient(Obj)\n","\n","\n","# SGD, Adam --> gObj  --> tune our weights\n","\n","# Obj_Trained\n","\n","# Prediction\n","\n"],"metadata":{"id":"xBJaSxBBReZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# [[0 0 0 1],\n","#  [0 1 0 0]\n","#  [1 0 0 0]]\n","\n","\n","#  caption_w@[1 1 0 1]"],"metadata":{"id":"vZWJpM-wQmgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# imgSet = sequence_Tensor['outfitSequencesImage'][0]\n","# imgSet.shape"],"metadata":{"id":"SJ4xkE4ZMAZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# feature_vector = resnetModel.model.predict(np.array(imgSet))\n","# feature_vector.shape"],"metadata":{"id":"2krvSVsYMIIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# image_caption_array = to_sequence_Array(all_sets[0], (224,224), fashion_tokens, path)"],"metadata":{"id":"1uAyZjsFH_eC","executionInfo":{"status":"ok","timestamp":1650720143145,"user_tz":-330,"elapsed":6693,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"59dda910-f73d-4835-99ed-c1a64c2b9b65"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive/MyDrive/Colab Notebooks/Capstone Project/Outfit_Processing/Data/Outfits/214181831\n"]}]},{"cell_type":"code","source":["# image_caption_array[0].shape, image_caption_array[1].shape"],"metadata":{"id":"qhSIXyfbL3rF","executionInfo":{"status":"ok","timestamp":1650720145214,"user_tz":-330,"elapsed":6,"user":{"displayName":"Arvinder Shinh","userId":"05567062736661194551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c02044c-ef54-42fd-8391-ff94c40f473f"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((8, 100352), (8, 2756))"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["# Image.fromarray(np.array(image_caption_array['img_seq'][4]))"],"metadata":{"id":"zfkIC6EiZIyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def oneHotEncoding(tokenIds, vectorLength):\n","#   zeroVector = [0]*vectorLength\n","#   oneHotVectors = [zeroVector[:i]+[1]+zeroVector[i+1:] for i in tokenIds]\n","#   return oneHotVectors\n","  \n","# # a1 = oneHotEncoding([2,5,8], 10)\n","# # a1"],"metadata":{"id":"i4tDoP_fy0O0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SUDO INCEPTION_V3 / RESNET  VNCON3_BN5C --> followed by average pooling --> output 512 dimentional \n","\n","\n","rank k prediction --> validation matrix (performance)\n","\n","seimis model (1,2) (2,3) "],"metadata":{"id":"xF5sN9wgWKwt"}},{"cell_type":"code","source":["# def inception_v3_sudo(images):\n","  \n","#   r = images.shape[1]*images.shape[2]\n","#   c = 2048\n","  \n","#   key = random.PRNGKey(7)\n","#   W  = random.normal(key, shape=(r,c))\n","\n","#   X1 = jnp.sum(images, axis=3)\n","#   X2 = jnp.reshape(X1, (-1, r))\n","#   inception_output = jnp.matmul(X2, W)\n","\n","#   return inception_output\n"],"metadata":{"id":"6o8H4D9MWJuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inception_Output = inception_v3_sudo(image_caption_array['img_seq'])\n","# inception_Output.shape"],"metadata":{"id":"7LvkfTYBWq6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visual_semantic = {'img_seq': inception_Output, 'caption_seq': a['caption_seq']}"],"metadata":{"id":"caGkiv_Aboz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# jnp.dtype(visual_semantic['img_seq']), jnp.dtype(visual_semantic['caption_seq']), visual_semantic['img_seq'].shape, visual_semantic['caption_seq'].shape"],"metadata":{"id":"fhFK9DFt2rLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inception_Output_batched = jnp.reshape(inception_Output, (inception_Output.shape[0], 1, inception_Output.shape[1]))\n","# inception_Output_batched.shape"],"metadata":{"id":"Sgz1dFc4d1Ov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all_sets = json.load(open(labels_file))"],"metadata":{"id":"hQk6WOIHGj2f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !unzip Data.zip"],"metadata":{"id":"8a50I-JvjBhL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(filename)\n","# with open(filename, \"rb\") as f:\n","#   encoded_image = f.read()"],"metadata":{"id":"2HTz33IY5dKN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"d5Xg8VjhphBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# image = Image.open('/content/gdrive/MyDrive/Colab Notebooks/Capstone Project/Outfit_Processing/Data/Outfits/120161271/1.jpg')\n","# # summarize some details about the image\n","# print(image.format)\n","# print(image.mode)\n","# print(image.size)\n","# # show the image\n","# image.show()"],"metadata":{"id":"DAnZYy8zA7jt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from matplotlib import image\n","# from matplotlib import pyplot"],"metadata":{"id":"YF0SLbOdB1Xd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data = image.imread('/content/gdrive/MyDrive/Colab Notebooks/Capstone Project/Outfit_Processing/Data/Outfits/120161271/1.jpg')\n","\n","# pyplot.imshow(data)"],"metadata":{"id":"speJko1_Bx68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a = [2,4,1,2,5]\n","# b = enumerate(a)\n","# list(b)\n","\n","# [2]*3"],"metadata":{"id":"AVwIYb_vh6E1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# img_jnp = jnp.array([np.array([1,2,3]), np.array([4,5,6])])\n","# img_jnp"],"metadata":{"id":"ZJ52BCqjCLh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a =  [1,2,3]\n","# a.extend([-1]*0)\n","# a\n","\n","    # img_jnp = jnp.array(img_numpy)"],"metadata":{"id":"E7VAJm4QICxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# len(a), a['caption_seq'][0].shape, a['img_seq'][0].shape\n","# b = [len(a['caption_seq'][i]) for i in range(len(a['caption_seq']))]\n","# b, len(a['caption_seq'][2][4])\n","# d = [sum(a['caption_seq'][1][i]) for i in range(len(a['caption_seq'][1]))]\n","# d\n","# a['caption_seq']"],"metadata":{"id":"SCW-akZAY9Vr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def fixedLengthImageAndCaptionSeq(imgSeq, captionSeq, fixedSeqLength, maxLength):\n","#   assert len(imgSeq) == len(captionSeq)\n","#   zeroVector = [0]*(dict_len+1)\n","#   zeroMatrix = [zeroVector]*maxLength\n","\n","#   l = len(imgSeq)\n","#   if l > fixedSeqLength:\n","#     return imgSeq[:fixedSeqLength], captionSeq[:fixedSeqLength]\n","#   elif l < fixedSeqLength:\n","#     return imgSeq+[imgSeq[-1]]*(fixedSeqLength-l), captionSeq+[zeroMatrix]*(fixedSeqLength-l)\n","#   else:\n","#     return imgSeq, captionSeq"],"metadata":{"id":"2ReSjTND1j15"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def nullFun():\n","#   return\n","\n","# # type(nullFun())\n","# # nullFun() == None\n","\n","# if nullFun():\n","#   print(\"Not Working\")\n","# else:\n","#   print('working')"],"metadata":{"id":"pgS1PzsRsLwf"},"execution_count":null,"outputs":[]}]}