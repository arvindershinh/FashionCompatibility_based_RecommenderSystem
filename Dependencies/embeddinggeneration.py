# -*- coding: utf-8 -*-
"""EmbeddingGeneration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LFNAdaXRnmAq_KR19dVCdIiM85034SC6
"""

import json
import os
import random
import sys
import pickle

import numpy as np
import pandas as pd

from PIL import Image
from numpy import asarray
import jax.numpy as jnp
import jax
from jax import jit
from jax import random

# from google.colab import drive
# drive.mount('/content/gdrive')

# sys.path.insert(0,'/content/gdrive/MyDrive/Colab Notebooks/Capstone Project/Dependencies')

# import transferlearningresnet as resnetModel

# """TEST DATA LOADING"""

# path = 'gdrive/MyDrive/Colab Notebooks/Capstone Project/Polyvore_Data/'
# json_file = os.path.join(path, 'Json Files','test_no_dup.json')

# all_sets = json.load(open(json_file))

# """PARAMETERS LOADING"""

# param_path = '/content/gdrive/MyDrive/Colab Notebooks/Capstone Project/params.p'

# params = pickle.load( open( param_path, "rb" ) )
# params.keys()

# params['linear']['w'].shape, params['visual_semantic']['wv'].shape

# """EMBEDDING GENERATION"""

# imgSize = (224,224,3)
# model_resnet = resnetModel.getResNetModel(imgSize)
# testData_path = 'gdrive/MyDrive/Colab Notebooks/Capstone Project/Polyvore_Data/Outfits'

def embeddingGenerator(image, img_size, model, embedding_params):
  Param_RNN, Param_VisualSemantic = embedding_params
  if image.mode != 'RGB':
    image = image.convert('RGB')
  img_resized = image.resize(img_size[:-1])
  img_numpy =  asarray(img_resized)
  image_feature = model.predict(np.array([img_numpy]))
  image_feature = image_feature.reshape([-1])

  image_embedding_RNN      =       jnp.dot(jnp.transpose(Param_RNN), image_feature)
  image_embedding_visualSemantic = jnp.dot(jnp.transpose(Param_VisualSemantic), image_feature)

  return image_embedding_RNN, image_embedding_visualSemantic

# def imageEmbedding(outfits, dataPath, img_size, model, embedding_params):
#   image_names = []
#   image_RNNs = []
#   image_visualSemantics = []
#   for outfit in outfits:
#     set_id = outfit['set_id']
#     outfit_path = os.path.join(dataPath, str(set_id))
#     if os.path.exists(outfit_path):
#       for image_info in outfit['items']:
#         image_name = set_id + "_" + str(image_info["index"])
#         image_path = os.path.join(outfit_path, str(image_info['index']) + '.jpg')
#         image = Image.open(image_path)
#         image_RNN, image_visualSemantic = embeddingGenerator(image, img_size, model, embedding_params)
#         image_names.append(image_name)
#         image_RNNs.append(image_RNN)
#         image_visualSemantics.append(image_visualSemantic)
        
#   return (image_names, np.array(image_RNNs), np.array(image_visualSemantics))

# test_features = imageEmbedding(all_sets, testData_path, imgSize, model_resnet, (params['linear']['w'], params['visual_semantic']['wv']))

# a,b,c = test_features

# len(a), type(a), b.shape, c.shape

# import pickle

# test_features_path = '/content/gdrive/MyDrive/Colab Notebooks/Capstone Project/test_features.p'

# pickle.dump( test_features, open( test_features_path, "wb" ) )

"""CACHE"""

# def imageEmbedding(outfits, dataPath, img_size, model, embedding_params):
#   test_features = {}
#   for outfit in outfits:
#     set_id = outfit['set_id']
#     outfit_path = os.path.join(dataPath, str(set_id))
#     if os.path.exists(outfit_path):
#       for image_info in outfit['items']:
#         image_name = set_id + "_" + str(image_info["index"])
#         image_path = os.path.join(outfit_path, str(image_info['index']) + '.jpg')
#         image = Image.open(image_path)
#         imageEmbeddings = embeddingGenerator(image, img_size, model, embedding_params)
#         test_features[image_name] = imageEmbeddings
        
#   return test_features

# test_features.keys(), test_features['119314458_3'][0].shape, test_features['119314458_3'][1].shape, type(test_features['119314458_3'][1])